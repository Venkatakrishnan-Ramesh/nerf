{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7415898,"sourceType":"datasetVersion","datasetId":4314081},{"sourceId":7415942,"sourceType":"datasetVersion","datasetId":4314100}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://drive.google.com/drive/folders/18bwm-RiHETRCS5yD9G00seFIcrJHIvD-","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://gitlab.com/venkatakrishnan.airender/FastNeRF.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd /kaggle/input/fastnerf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd fast_nerf_kaggle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n# from torchsummary import summary\nimport os \n# from torch.utils.tensorboard import SummaryWriter\nimport sys\nimport gc\nimport argparse\nfrom itertools import chain\n# import atexit\n            \nclass FastNerf(nn.Module):\n    def __init__(self, embedding_dim_pos=10, embedding_dim_direction=4, hidden_dim_pos=384, hidden_dim_dir=128, D=8):\n        super(FastNerf, self).__init__()\n\n        self.Fpos = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + 3, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, 3 * D + 1), )\n\n        self.Fdir = nn.Sequential(nn.Linear(embedding_dim_direction * 6 + 3, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, D), )\n\n        self.embedding_dim_pos = embedding_dim_pos\n        self.embedding_dim_direction = embedding_dim_direction\n        self.D = D\n\n    @staticmethod\n    def positional_encoding(x, L):\n        out = [x]\n        # print(out[0].shape,\"OUT SHAPE\")\n        \n        print(\"x\",x.shape)\n        for j in range(L):\n            out.append(torch.sin(2 ** j * x))\n            out.append(torch.cos(2 ** j * x))\n        # print(torch.cat(out, dim=1).size,\"size\")\n        \n        return torch.cat(out, dim=1)\n\n    def forward(self, o, d):\n        # print(o.shape,d.shape)\n        # print(\"POSITIONAL ENCODING\")\n        sigma_uvw = self.Fpos(self.positional_encoding(o, self.embedding_dim_pos))\n        # print(\"sigma_uvw\",sigma_uvw.shape)\n        \n        \n        sigma = torch.nn.functional.softplus(sigma_uvw[:, 0][..., None])  # [batch_size, 1]\n        uvw = torch.sigmoid(sigma_uvw[:, 1:].reshape(-1, 3, self.D))  # [batch_size, 3, D]\n        \n        # print(\"POSITIONAL ENCODING 2\")\n        beta = torch.softmax(self.Fdir(self.positional_encoding(d, self.embedding_dim_direction)), -1)\n        color = (beta.unsqueeze(1) * uvw).sum(-1)  # [batch_size, 3]\n\n        return color, sigma\n\ndef softmax_(x, dim):\n        x_max = x.max(dim=dim, keepdim=True).values\n        x.sub_(x_max).exp_().div_(x.sum(dim=dim, keepdim=True))\n        \nclass Cache(nn.Module):\n    def __init__(self, model, scale, device, Np, Nd):\n        super(Cache, self).__init__()\n\n        with torch.no_grad():\n            # Position\n            x, y, z = torch.meshgrid([torch.linspace(-scale / 2, scale / 2, Np).to(device),\n                                      torch.linspace(-scale / 2, scale / 2, Np).to(device),\n                                      torch.linspace(-scale / 2, scale / 2, Np).to(device)])\n            # print(x.shape,\"x shape\")\n            # print(y.shape,\"y shape\")\n            # print(z.shape,\"z shape\")\n            xyz = torch.cat((x.reshape(-1, 1), y.reshape(-1, 1), z.reshape(-1, 1)), dim=1)\n            # print(xyz.shape,\"xyz shape\")\n            sigma_uvw = model.Fpos(model.positional_encoding(xyz, model.embedding_dim_pos))\n            self.sigma_uvw = sigma_uvw.reshape((Np, Np, Np, -1))\n            # Direction\n            xd, yd = torch.meshgrid([torch.linspace(-scale / 2, scale / 2, Nd).to(device),\n                                     torch.linspace(-scale / 2, scale / 2, Nd).to(device)])\n            xyz_d = torch.cat((xd.reshape(-1, 1), yd.reshape(-1, 1),\n                               torch.sqrt((1 - xd ** 2 - yd ** 2).clip(0, 1)).reshape(-1, 1)), dim=1)\n            beta = model.Fdir(model.positional_encoding(xyz_d, model.embedding_dim_direction))\n            self.beta = beta.reshape((Nd, Nd, -1))\n            print (\"Beta in cache \" ,self.beta.shape)\n\n        self.scale = scale\n        self.Np = Np\n        self.Nd = Nd\n        self.D = model.D\n    \n    \n\n    def forward(self, x, d):\n        color = torch.zeros_like(x)\n        sigma = torch.zeros((x.shape[0], 1), device=x.device)\n\n#         print(\"x\",x.shape)\n#         print(\"d\",d.shape)\n\n        mask = (x[:, 0].abs() < (self.scale / 2)) & (x[:, 1].abs() < (self.scale / 2)) & (x[:, 2].abs() < (self.scale / 2))\n        # mask is done to check if the x is within the range of scale/2 , any other method? to do the same thing\n        # Position\n        idx = (x[mask] / (self.scale / self.Np) + self.Np / 2).long().clip(0, self.Np - 1)\n#         print(\"indexed shape\",self.sigma_uvw[idx[:, 0], idx[:, 1], idx[:, 2]].shape)\n#         print(\"idx\",idx.shape)\n#         print(\"self.sigma_uvw\",self.sigma_uvw.shape)\n#         print(\"mask\",mask.shape)\n        sigma_uvw = self.sigma_uvw[idx[:, 0], idx[:, 1], idx[:, 2]]\n#         print(self.beta[idx[:, 0], idx[:, 1]].shape)\n#         print(\"beta_indexed\",idx[:, 0].shape,idx[:, 1].shape,idx[:, 2].shape)\n#         print(\"sigma_uvw\",sigma_uvw.shape)\n#         print(\"beta\",self.beta.shape)\n        # Direction\n        # idx = (d[mask] * self.Nd).long().clip(0, self.Nd - 1)\n        beta = softmax_(self.beta[idx[:, 0], idx[:, 1]], -1)\n        beta=self.beta[idx[:, 0], idx[:, 1]]\n        # \n        # beta=torch.softmax(self.beta[idx[:1000, 0], idx[:1000, 1]], -1)\n\n        sigma[mask] = torch.nn.functional.softplus(sigma_uvw[:, 0][..., None]) \n#         print(\"sigma\",sigma.shape)\n        #uvw = torch.sigmoid_(sigma_uvw[:, 1:])\n        # print(\"uvw\",uvw.shape)\n        # print(\"uvw_reshaped\" , uvw.reshape(-1, 3, self.D).shape)\n        uvw = torch.sigmoid_(sigma_uvw[:, 1:].reshape(-1, 3, self.D))\n#         print(\"uvw\",uvw.shape)\n        uvw.mul_(beta.unsqueeze(1))\n#         print(\"uvw_multiplied\",uvw.shape)\n        color[mask] = uvw.sum(-1) \n        return color, sigma\n\ndef compute_accumulated_transmittance(alphas):\n    accumulated_transmittance = torch.cumprod(alphas, 1)\n    return torch.cat((torch.ones((accumulated_transmittance.shape[0], 1), device=alphas.device),\n                      accumulated_transmittance[:, :-1]), dim=-1)\n\ndef render_rays(nerf_model, ray_origins, ray_directions, hn=0, hf=0.5, nb_bins=192):\n    device = ray_origins.device\n    t = torch.linspace(hn, hf, nb_bins, device=device).expand(ray_origins.shape[0], nb_bins)\n    print(\"t\",t.shape)\n    # Perturb sampling along each ray.\n    mid = (t[:, :-1] + t[:, 1:]) / 2.\n    lower = torch.cat((t[:, :1], mid), -1)\n    upper = torch.cat((mid, t[:, -1:]), -1)\n#     print(\"lower\",lower.shape)\n#     print(\"upper\",upper.shape)\n    u = torch.rand(t.shape, device=ray_origins.device)\n    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n#     print(\"t\",t.shape)\n    delta = torch.cat((t[:, 1:] - t[:, :-1], torch.tensor([1e10], device=device).expand(ray_origins.shape[0], 1)), -1)\n#     print(\"delta\",delta.shape)\n    x = ray_origins.unsqueeze(1) + t.unsqueeze(2) * ray_directions.unsqueeze(1)  # [batch_size, nb_bins, 3]\n#     print(\"x\",x.shape)\n    ray_directions = ray_directions.expand(nb_bins, ray_directions.shape[0], 3).transpose(0, 1)\n#     print(\"ray_directions\",ray_directions.shape)\n    \n    colors, sigma = nerf_model(x.reshape(-1, 3), ray_directions.reshape(-1, 3))\n#     print(\"colors\",colors.shape)\n    \n    colors = colors.reshape(x.shape)\n    sigma = sigma.reshape(x.shape[:-1])\n\n    alpha = 1 - torch.exp(-sigma * delta)  # [batch_size, nb_bins]\n    weights = compute_accumulated_transmittance(1 - alpha).unsqueeze(2) * alpha.unsqueeze(2)\n    c = (weights * colors).sum(dim=1)  # Pixel values\n    weight_sum = weights.sum(-1).sum(-1) # Regularization for white background\n    return c + 1 - weight_sum.unsqueeze(-1)\n\n\n@torch.no_grad()\ndef test(model, hn, hf, dataset, img_index=0, nb_bins=192, H=400, W=400):\n    # print(\"test:img_index:\",img_index)\n    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n    print(\"test:ray_origins:\",ray_origins.shape)\n    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n    print(\"test:ray_directions:\",ray_directions.shape)\n    \n    regenerated_px_values = render_rays(model, ray_origins.to(device), ray_directions.to(device), hn=hn, hf=hf,\n                                        nb_bins=nb_bins)\n    \n    \n    \n#     print(\"test:regenerated_px_values:\",regenerated_px_values.shape)\n    # print(\"test:regenerated_px_values\",regenerated_px_values.shape)\n    # print(\"test:regenerated_px_values:1:\",regenerated_px_values.data.cpu().numpy().reshape(H, W, 3).clip(0, 1).shape)\n\n    fig = plt.figure()\n    fig.set_size_inches(H, W)\n    plt.imshow(regenerated_px_values.data.cpu().numpy().reshape(H, W, 3).clip(0, 1))\n    plt.axis('off')\n    plt.savefig(f'novel_views/img_test_{img_index}.png', dpi=1)\n    print('Render successful{img_index}')\n    # plt.savefig(f'novel_views/img_{img_index}.png', bbox_inches='tight')\n    plt.close()\n\n    # generated_px_values = dataset[img_index * H * W: (img_index + 1) * H * W, 6:]\n    # fig=plt.figure()\n    # fig.set_size_inches(H, W)\n    # plt.imshow(generated_px_values.data.cpu().numpy().reshape(H, W, 3).clip(0, 1))\n    # plt.axis('off')\n    # plt.savefig(f'novel_views/img_generated_{img_index}.png', dpi=1)\n    # print('Testing successful_{img_index}')\n\ndef cleanup():\n    \"\"\"\n    Cleanup function to release GPU resources.\n    \"\"\"\n    # Clear the GPU cache\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n\ndef train(nerf_model, optimizer, scheduler, data_loader, device='cpu', hn=0, hf=1, nb_epochs=int(1e5),\n          nb_bins=192):\n    # print(\"dataloader\", type(data_loader))\n    training_loss = []\n    for _ in (range(nb_epochs)):\n        for ep, batch in enumerate(tqdm(data_loader)):\n            ray_origins = batch[:, :3].to(device)\n            ray_directions = batch[:, 3:6].to(device)\n            ground_truth_px_values = batch[:, 6:].to(device)\n            regenerated_px_values = render_rays(nerf_model, ray_origins, ray_directions, hn=hn, hf=hf, nb_bins=nb_bins)\n            loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            training_loss.append(loss.item())\n        scheduler.step()\n        torch.save(nerf_model.cpu(), 'nerf_model')\n        nerf_model.to(device)\n    return training_loss\n\ndef pattern(dataset_size):\n    # Set the device to GPU if available\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    # Create sequence as PyTorch tensor\n    seq = torch.arange(dataset_size, device=device)\n    # Define steps and calculations\n    step1 = 32\n    step2 = 400\n    step3 = step2 // 2\n    subt = step1 // 2\n    range_start = step3 - subt\n\n    # First Transformation\n    indices = torch.arange(range_start, seq.numel(), step2, device=device)\n    result = torch.cat([seq[i:i+step1] for i in indices])\n\n    # Second Transformation\n    step11 = step1 * step1\n    range_start1 = range_start * step1\n    step21 = range_start1 * 2 + step11\n    indices1 = torch.arange(range_start1, result.numel(), step21, device=device)\n    result1 = torch.cat([result[i:i+step11] for i in indices1])\n\n    # Converting result back to CPU for return, if needed\n    return result1.cpu().numpy()\n\n\ndef main():\n    # Parse arguments\n#     parser = argparse.ArgumentParser(description=\"Neural Rendering with FastNeRF\")\n#     parser.add_argument('--mode', type=str, choices=['train', 'test'], required=True,\n#                         help=\"Mode to run the script: 'train' or 'test'\")\n#     args = parser.parse_args()\n    \n    # images , labels = training_dataset\n    # print(images.shape)\n    # sys.exit()\n#     testing_dataset = torch.from_numpy(np.load('testing_data.pkl', allow_pickle=True))\n    model = FastNerf().to(device)\n    model = torch.nn.DataParallel(model, device_ids = [0,1])\n#     atexit.register(cleanup)\n\n#     if args.mode == 'train':\n    training_dataset = torch.from_numpy(np.load('/kaggle/input/training/training_data.pkl', allow_pickle=True))\n    training_dataset_shape = np.shape(training_dataset)\n    # print(\"training_dataset_shape\",training_dataset_shape)\n    #pattern1=pattern(training_dataset_shape[0])\n    # print(\"pattern1\",pattern1)\n    #training_dataset_new=training_dataset[pattern1,:]\n    #training_dataset_new_shape = np.shape(training_dataset_new)\n    # print(\"training_dataset_new_shape\",training_dataset_new_shape\n    model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(model_optimizer, milestones=[2, 4, 8], gamma=0.5)\n    data_loader = DataLoader(training_dataset, batch_size=1024, shuffle=True)\n    train(model, model_optimizer, scheduler, data_loader, nb_epochs=16, device=device, hn=2, hf=6)\n\n    # Save the model\n    model_path = 'model.pth'\n    torch.save(model, model_path)\n    model_size = os.path.getsize(model_path)\n    print(f\"Size of the saved model on disk: {model_size / (1024*1024)} MB\")\n\n#     elif args.mode == 'test':\n#         model = torch.load('model.pth')\n#         # model.eval()\n#         cache = Cache(model, 2.2, 'cuda', 64, 64)\n#         print(\"cache\")\n        \n#         for idx in range(200):\n#             test(cache, 2., 6., testing_dataset, img_index=idx, nb_bins=12, H=400, W=400)\n#             torch.cuda.empty_cache()\n\nimport time \nif __name__ == '__main__':\n    start=time.time()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    main()\n    end=time.time()\n    print(end-start,\"Time\")\n    \n\n# %%\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n# from torchsummary import summary\nimport os \nfrom torch.utils.tensorboard import SummaryWriter\nimport sys\nimport gc\n            \nclass FastNerf(nn.Module):\n    def __init__(self, embedding_dim_pos=10, embedding_dim_direction=4, hidden_dim_pos=384, hidden_dim_dir=128, D=8):\n        super(FastNerf, self).__init__()\n\n        self.Fpos = nn.Sequential(nn.Linear(embedding_dim_pos * 6 + 3, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, hidden_dim_pos), nn.ReLU(),\n                                  nn.Linear(hidden_dim_pos, 3 * D + 1), )\n\n        self.Fdir = nn.Sequential(nn.Linear(embedding_dim_direction * 6 + 3, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, hidden_dim_dir), nn.ReLU(),\n                                  nn.Linear(hidden_dim_dir, D), )\n\n        self.embedding_dim_pos = embedding_dim_pos\n        self.embedding_dim_direction = embedding_dim_direction\n        self.D = D\n\n    @staticmethod\n    def positional_encoding(x, L):\n        out = [x]\n        print(out[0].shape,\"OUT SHAPE\")\n        print(\"x\",x.shape)\n        for j in range(L):\n            out.append(torch.sin(2 ** j * x))\n            out.append(torch.cos(2 ** j * x))\n        print(torch.cat(out, dim=1).size,\"size\")\n        return torch.cat(out, dim=1)\n\n    @staticmethod\n    def positional_encoding1(x, L):\n        out = [x]\n        print(out[0].shape,\"OUT SHAPE1\")\n        print(\"x\",x.shape)\n        for j in range(L):\n            out.append(torch.sin(2 ** j * x))\n            out.append(torch.cos(2 ** j * x))\n        print(torch.cat(out, dim=1).size,\"size1\")\n        return torch.cat(out, dim=1)\n\n    def forward(self, o, d):\n        print(o.shape,d.shape)\n        print(\"POSITIONAL ENCODING\")\n        sigma_uvw = self.Fpos(self.positional_encoding(o, self.embedding_dim_pos))\n        print(sigma_uvw.shape)\n        # Ensure the reshape operation is valid\n        # expected_num_elements = sigma_uvw.shape[0] * 3 * self.D\n        # actual_num_elements = sigma_uvw.numel() - sigma_uvw.shape[0]\n        # if expected_num_elements != actual_num_elements:\n        #     raise ValueError(f\"Cannot reshape sigma_uvw of total size {actual_num_elements} into [-1, 3, {self.D}]\")\n\n        #  #Debugging: Check the shape of sigma_uvw before reshape\n        # print(f\"Shape of sigma_uvw: {sigma_uvw.shape}\")\n        # expected_shape = (-1, 3, self.D)\n\n        # if sigma_uvw.shape[1] != expected_shape[1] * expected_shape[2]:\n        #     raise ValueError(f\"Shape mismatch for reshape. Expected total size for reshape is {expected_shape[1] * expected_shape[2]}, but got {sigma_uvw.shape[1]}\")\n\n        # Reshape operation\n        # uvw = torch.sigmoid(sigma_uvw[:, 1:].reshape(*expected_shape))\n\n        sigma = torch.nn.functional.softplus(sigma_uvw[:, 0][..., None])  # [batch_size, 1]\n        uvw = torch.sigmoid(sigma_uvw[:, 1:].reshape(-1, 3, self.D))  # [batch_size, 3, D]\n        \n        print(\"POSITIONAL ENCODING 2\")\n        beta = torch.softmax(self.Fdir(self.positional_encoding(d, self.embedding_dim_direction)), -1)\n        color = (beta.unsqueeze(1) * uvw).sum(-1)  # [batch_size, 3]\n\n        return color, sigma\n\n\nclass Cache(nn.Module):\n    def __init__(self, model, scale, device, Np, Nd):\n        super(Cache, self).__init__()\n\n        with torch.no_grad():\n            # Position\n            x, y, z = torch.meshgrid([torch.linspace(-scale / 2, scale / 2, Np).to(device),\n                                      torch.linspace(-scale / 2, scale / 2, Np).to(device),\n                                      torch.linspace(-scale / 2, scale / 2, Np).to(device)])\n            print(x.shape,\"x shape\")\n            print(y.shape,\"y shape\")\n            print(z.shape,\"z shape\")\n            xyz = torch.cat((x.reshape(-1, 1), y.reshape(-1, 1), z.reshape(-1, 1)), dim=1)\n            print(xyz.shape,\"xyz shape\")\n\n            temp = model.positional_encoding1(xyz, model.embedding_dim_pos)\n            sigma_uvw = model.Fpos(model.positional_encoding(xyz, model.embedding_dim_pos))\n            self.sigma_uvw = sigma_uvw.reshape((Np, Np, Np, -1))\n            # Direction\n            xd, yd = torch.meshgrid([torch.linspace(-scale / 2, scale / 2, Nd).to(device),\n                                     torch.linspace(-scale / 2, scale / 2, Nd).to(device)])\n            xyz_d = torch.cat((xd.reshape(-1, 1), yd.reshape(-1, 1),\n                               torch.sqrt((1 - xd ** 2 - yd ** 2).clip(0, 1)).reshape(-1, 1)), dim=1)\n            beta = model.Fdir(model.positional_encoding(xyz_d, model.embedding_dim_direction))\n            self.beta = beta.reshape((Nd, Nd, -1))\n\n        self.scale = scale\n        self.Np = Np\n        self.Nd = Nd\n        self.D = model.D\n\n    def forward(self, x, d):\n        color = torch.zeros_like(x)\n        sigma = torch.zeros((x.shape[0], 1), device=x.device)\n\n        mask = (x[:, 0].abs() < (self.scale / 2)) & (x[:, 1].abs() < (self.scale / 2)) & (x[:, 2].abs() < (self.scale / 2))\n        # Position\n        idx = (x[mask] / (self.scale / self.Np) + self.Np / 2).long().clip(0, self.Np - 1)\n        sigma_uvw = self.sigma_uvw[idx[:, 0], idx[:, 1], idx[:, 2]]\n        # Direction\n        idx = (d[mask] * self.Nd).long().clip(0, self.Nd - 1)\n        beta = torch.softmax(self.beta[idx[:, 0], idx[:, 1]], -1)\n\n        sigma[mask] = torch.nn.functional.softplus(sigma_uvw[:, 0][..., None])  # [batch_size, 1]\n        uvw = torch.sigmoid(sigma_uvw[:, 1:].reshape(-1, 3, self.D))  # [batch_size, 3, D]\n        color[mask] = (beta.unsqueeze(1) * uvw).sum(-1)  # [batch_size, 3]\n        return color, sigma\n\n\ndef compute_accumulated_transmittance(alphas):\n    accumulated_transmittance = torch.cumprod(alphas, 1)\n    return torch.cat((torch.ones((accumulated_transmittance.shape[0], 1), device=alphas.device),\n                      accumulated_transmittance[:, :-1]), dim=-1)\n\n\ndef render_rays(nerf_model, ray_origins, ray_directions, hn=0, hf=0.5, nb_bins=192):\n    device = ray_origins.device\n    t = torch.linspace(hn, hf, nb_bins, device=device).expand(ray_origins.shape[0], nb_bins)\n    # Perturb sampling along each ray.\n    mid = (t[:, :-1] + t[:, 1:]) / 2.\n    lower = torch.cat((t[:, :1], mid), -1)\n    upper = torch.cat((mid, t[:, -1:]), -1)\n    u = torch.rand(t.shape, device=ray_origins.device)\n    t = lower + (upper - lower) * u  # [batch_size, nb_bins]\n    delta = torch.cat((t[:, 1:] - t[:, :-1], torch.tensor([1e10], device=device).expand(ray_origins.shape[0], 1)), -1)\n\n    x = ray_origins.unsqueeze(1) + t.unsqueeze(2) * ray_directions.unsqueeze(1)  # [batch_size, nb_bins, 3]\n    ray_directions = ray_directions.expand(nb_bins, ray_directions.shape[0], 3).transpose(0, 1)\n\n    colors, sigma = nerf_model(x.reshape(-1, 3), ray_directions.reshape(-1, 3))\n    colors = colors.reshape(x.shape)\n    sigma = sigma.reshape(x.shape[:-1])\n\n    alpha = 1 - torch.exp(-sigma * delta)  # [batch_size, nb_bins]\n    weights = compute_accumulated_transmittance(1 - alpha).unsqueeze(2) * alpha.unsqueeze(2)\n    c = (weights * colors).sum(dim=1)  # Pixel values\n    weight_sum = weights.sum(-1).sum(-1) # Regularization for white background\n    return c + 1 - weight_sum.unsqueeze(-1)\n\n\n@torch.no_grad()\ndef test(model, hn, hf, dataset, img_index=0, nb_bins=192, H=400, W=400):\n    print(\"test:img_index:\",img_index)\n    ray_origins = dataset[img_index * H * W: (img_index + 1) * H * W, :3]\n    ray_directions = dataset[img_index * H * W: (img_index + 1) * H * W, 3:6]\n    regenerated_px_values = render_rays(model, ray_origins.to(device), ray_directions.to(device), hn=hn, hf=hf,\n                                        nb_bins=nb_bins)\n    print(\"test:regenerated_px_values\",regenerated_px_values.shape)\n    print(\"test:regenerated_px_values:1:\",regenerated_px_values.data.cpu().numpy().reshape(H, W, 3).clip(0, 1).shape)\n\n    fig = plt.figure()\n    fig.set_size_inches(H, W)\n    plt.imshow(regenerated_px_values.data.cpu().numpy().reshape(H, W, 3).clip(0, 1))\n    plt.axis('off')\n    plt.savefig(f'novel_views/img_test_{img_index}.png', dpi=1)\n    # plt.savefig(f'novel_views/img_{img_index}.png', bbox_inches='tight')\n    plt.close()\n\n\ndef train(nerf_model, optimizer, scheduler, data_loader, device='cpu', hn=0, hf=1, nb_epochs=int(1e5),\n          nb_bins=192):\n    training_loss = []\n    for _ in (range(nb_epochs)):\n        for ep, batch in enumerate(tqdm(data_loader)):\n            ray_origins = batch[:, :3].to(device)\n            ray_directions = batch[:, 3:6].to(device)\n            ground_truth_px_values = batch[:, 6:].to(device)\n            regenerated_px_values = render_rays(nerf_model, ray_origins, ray_directions, hn=hn, hf=hf, nb_bins=nb_bins)\n            loss = ((ground_truth_px_values - regenerated_px_values) ** 2).sum()\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            training_loss.append(loss.item())\n        scheduler.step()\n        torch.save(nerf_model.cpu(), 'nerf_model')\n        nerf_model.to(device)\n    return training_loss\n\n\nif __name__ == '__main__':\n    device = 'cuda'\n    # writer = SummaryWriter()\n    training_dataset = torch.from_numpy(np.load('/kaggle/input/training/training_data.pkl', allow_pickle=True))\n   # testing_dataset = torch.from_numpy(np.load('rtrain.pkl', allow_pickle=True))\n    model = FastNerf().to(device)\n    model = torch.nn.DataParallel(model, device_ids = [0,1])\n    model_optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(model_optimizer, milestones=[2, 4, 8], gamma=0.5)\n    data_loader = DataLoader(training_dataset, batch_size=4096, shuffle=True)\n    train(model, model_optimizer, scheduler, data_loader, nb_epochs=16, device=device, hn=2, hf=6)\n    # # Save the model\n    model_path = 'model.pth'  # Define the file path as a string\n    torch.save(model, model_path)  # Save the model's state_dict\n\n    # Now, check the size of the saved model file\n    import os\n    model_size = os.path.getsize(model_path)\n    print(f\"Size of the saved model on disk: {model_size / (1024*1024)} MB\")\n\n    # torch.save('model.pth', model)\n    # model_path = 'model.pth'\n    # model_size = os.path.getsize(model_path)\n\n    # print(f\"Size of the saved model on disk: {model_size} bytes\")\n\n    # # Call summary with both input shapes\n#     input_shape_o = [3]\n#     input_shape_d = [3]\n#     summary(model, [input_shape_o, input_shape_d])\n\n    # cache = Cache(model, 2.2, device, 192, 128)\n#     cache = Cache(model, 2.2, device, 96, 96)\n\n    # del cache, data_loader, scheduler, model_optimizer, model, training_dataset, testing_dataset, device\n    # gc.collect()\n    \n    # import ctypes\n    # libc = ctypes.CDLL(\"libc.so.6\")\n    # libc.malloc_trim(0)\n\n#     for idx in range(1):\n#         test(cache, 2., 6., testing_dataset, img_index=idx, nb_bins=192, H=2, W=5)\n#     # for idx in range(200):\n#         # test(cache, 2., 6., testing_dataset, img_index=idx, nb_bins=192, H=400, W=400)\n# # %%\n\n# model = torch.load('model.pth')\n# model.eval()\n# for idx in range(1):\n#         test(cache, 2., 6., testing_dataset, img_index=idx, nb_bins=192, H=2, W=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T17:26:09.753613Z","iopub.execute_input":"2024-01-19T17:26:09.753992Z","iopub.status.idle":"2024-01-19T17:27:33.024308Z","shell.execute_reply.started":"2024-01-19T17:26:09.753960Z","shell.execute_reply":"2024-01-19T17:27:33.023023Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n  0%|          | 0/3907 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5de4c759e0> size\n<built-in method size of Tensor object at 0x7a5d1519d850> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5d1519f060> size\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5d1519cae0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/3907 [00:04<5:05:32,  4.69s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7b0d60> size\n<built-in method size of Tensor object at 0x7a5bed7b02c0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7b0d10> size\n<built-in method size of Tensor object at 0x7a5bed7b0f40> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 2/3907 [00:05<2:36:07,  2.40s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a90d0> size\n<built-in method size of Tensor object at 0x7a5bed7a9170> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9260> size\n<built-in method size of Tensor object at 0x7a5bed7a9350> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 3/3907 [00:06<1:44:42,  1.61s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3])torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa070> size\n<built-in method size of Tensor object at 0x7a5bed7aa1b0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa2a0> size\n<built-in method size of Tensor object at 0x7a5bed7aa340> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 4/3907 [00:06<1:20:34,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aaa70> size\n<built-in method size of Tensor object at 0x7a5bed7aab10> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aac50> size\n<built-in method size of Tensor object at 0x7a5bed7aa200> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 5/3907 [00:07<1:07:07,  1.03s/it]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aaa20> size\n<built-in method size of Tensor object at 0x7a5bed7aa7f0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aaca0> size\n<built-in method size of Tensor object at 0x7a5bed7a8590> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 6/3907 [00:08<59:02,  1.10it/s]  ","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8810> size\n<built-in method size of Tensor object at 0x7a5bed7a93f0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa8e0> size\n<built-in method size of Tensor object at 0x7a5bed7a8770> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 7/3907 [00:08<53:45,  1.21it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9fd0> size\n<built-in method size of Tensor object at 0x7a5bed7aa020> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9d00> size\n<built-in method size of Tensor object at 0x7a5bed7a8fe0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 8/3907 [00:09<50:22,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3])torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab3d0> size\n<built-in method size of Tensor object at 0x7a5bed7a8a40> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab4c0> size\n<built-in method size of Tensor object at 0x7a5bed7aae30> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 9/3907 [00:10<48:08,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9030> size\n<built-in method size of Tensor object at 0x7a5bed7a8a40> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9f30> size\n<built-in method size of Tensor object at 0x7a5bed7a8090> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 10/3907 [00:10<46:38,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aba10> size\n<built-in method size of Tensor object at 0x7a5bed7abab0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abb50> size\n<built-in method size of Tensor object at 0x7a5bed7abc90> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 11/3907 [00:11<45:36,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa160> size\n<built-in method size of Tensor object at 0x7a5bed7aaa70> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa610> size\n<built-in method size of Tensor object at 0x7a5bed7a90d0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 12/3907 [00:12<44:59,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a90d0> size\n<built-in method size of Tensor object at 0x7a5bed7ab150> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8040> size\n<built-in method size of Tensor object at 0x7a5bed7ab420> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 13/3907 [00:12<44:26,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abdd0> size\n<built-in method size of Tensor object at 0x7a5bed7abf10> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8360> size\n<built-in method size of Tensor object at 0x7a5bed7abba0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 14/3907 [00:13<44:14,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5cda708a90> size\n<built-in method size of Tensor object at 0x7a5cda708540> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5cda708680> size\n<built-in method size of Tensor object at 0x7a5d1519f1a0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 15/3907 [00:14<44:00,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa0c0> size\n<built-in method size of Tensor object at 0x7a5bed7aa0c0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7c4220> size\n<built-in method size of Tensor object at 0x7a5bed7aa2a0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 16/3907 [00:14<43:48,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa8e0> size\n<built-in method size of Tensor object at 0x7a5bed7a8900> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aaac0> size\n<built-in method size of Tensor object at 0x7a5bed7aa8e0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 17/3907 [00:15<43:41,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9080> size\n<built-in method size of Tensor object at 0x7a5bed7abe20> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8590> size\n<built-in method size of Tensor object at 0x7a5bed7ab1a0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 18/3907 [00:16<43:34,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aba10> size\n<built-in method size of Tensor object at 0x7a5bed7aaca0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa6b0> size\n<built-in method size of Tensor object at 0x7a5bed7ab4c0> size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 19/3907 [00:16<43:31,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9e90> size\n<built-in method size of Tensor object at 0x7a5bed7aaca0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab830> size\n<built-in method size of Tensor object at 0x7a5bed7abbf0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 20/3907 [00:17<43:27,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abba0> size\n<built-in method size of Tensor object at 0x7a5bed7a9490> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8810> size\n<built-in method size of Tensor object at 0x7a5bed7ab6f0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 21/3907 [00:18<50:00,  1.29it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3])torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9b70> size\n<built-in method size of Tensor object at 0x7a5bed7a9350> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8cc0> size\n<built-in method size of Tensor object at 0x7a5bed7a92b0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 22/3907 [00:19<48:01,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d030> size\n<built-in method size of Tensor object at 0x7a5c2225c900> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d580> size\n<built-in method size of Tensor object at 0x7a5c2225cef0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 23/3907 [00:19<46:37,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e8e0> size\n<built-in method size of Tensor object at 0x7a5c2225da30> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225eb60> size\n<built-in method size of Tensor object at 0x7a5c2225e520> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 24/3907 [00:20<45:37,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa2f0> size\n<built-in method size of Tensor object at 0x7a5bed7ab3d0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8770> size\n<built-in method size of Tensor object at 0x7a5bed7a8950> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 25/3907 [00:21<44:53,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aade0> size\n<built-in method size of Tensor object at 0x7a5bed7ab150> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9210> size\n<built-in method size of Tensor object at 0x7a5bed7ab060> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 26/3907 [00:21<44:24,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e020> size\n<built-in method size of Tensor object at 0x7a5c2225e200> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d300> size\n<built-in method size of Tensor object at 0x7a5c2225dc10> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 27/3907 [00:22<44:03,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225dd00> size\n<built-in method size of Tensor object at 0x7a5c2225c4a0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ebb0> size\n<built-in method size of Tensor object at 0x7a5c2225d350> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 28/3907 [00:23<44:04,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f1a0> size\n<built-in method size of Tensor object at 0x7a5c2225f2e0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f380> size\n<built-in method size of Tensor object at 0x7a5c2225f470> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 29/3907 [00:23<43:49,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fd80> size\n<built-in method size of Tensor object at 0x7a5c2225fe70> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ff60> size\n<built-in method size of Tensor object at 0x7a5c2225ff60> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 30/3907 [00:24<43:40,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aad40> size\n<built-in method size of Tensor object at 0x7a5bed7ab8d0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9030> size\n<built-in method size of Tensor object at 0x7a5bed7ab420> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 31/3907 [00:25<43:34,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab880> size\n<built-in method size of Tensor object at 0x7a5bed7a9d50> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8e50> size\n<built-in method size of Tensor object at 0x7a5bed7aafc0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 32/3907 [00:25<43:33,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e110> size\n<built-in method size of Tensor object at 0x7a5c2225c270> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f1a0> size\n<built-in method size of Tensor object at 0x7a5c2225ddf0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 33/3907 [00:26<43:25,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ea20> size\n<built-in method size of Tensor object at 0x7a5c2225f560> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d800> size\n<built-in method size of Tensor object at 0x7a5c2225f970> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 34/3907 [00:27<43:32,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f290> size\n<built-in method size of Tensor object at 0x7a5c2225dfd0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d9e0> size\n<built-in method size of Tensor object at 0x7a5c2225d580> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 35/3907 [00:27<43:30,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aacf0> size\n<built-in method size of Tensor object at 0x7a5bed7a9a80> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab5b0> size\n<built-in method size of Tensor object at 0x7a5bed7abfb0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 36/3907 [00:28<43:24,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a91c0> size\n<built-in method size of Tensor object at 0x7a5bed7a8270> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abf60> size\n<built-in method size of Tensor object at 0x7a5bed7abf60> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 37/3907 [00:29<43:22,  1.49it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fe20> size\n<built-in method size of Tensor object at 0x7a5c2225ea70> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ea70> size\n<built-in method size of Tensor object at 0x7a5c2225c9f0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 38/3907 [00:29<43:27,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cae0> size\n<built-in method size of Tensor object at 0x7a5c2225f2e0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f060> size\n<built-in method size of Tensor object at 0x7a5c2225d210> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 39/3907 [00:30<43:31,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abf10> size\n<built-in method size of Tensor object at 0x7a5bed7aa1b0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aabb0> size\n<built-in method size of Tensor object at 0x7a5bed7a8b30> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 40/3907 [00:31<43:28,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9c10> size\n<built-in method size of Tensor object at 0x7a5bed7aa430> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7abc40> size\n<built-in method size of Tensor object at 0x7a5bed7a82c0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 41/3907 [00:31<43:33,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d080> size\n<built-in method size of Tensor object at 0x7a5c2225c680> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225c4a0> size\n<built-in method size of Tensor object at 0x7a5c2225eed0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 42/3907 [00:32<43:34,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9940> size\n<built-in method size of Tensor object at 0x7a5bed7a9b20> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab100> size\n<built-in method size of Tensor object at 0x7a5bed7ab880> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 43/3907 [00:33<43:29,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab7e0> size\n<built-in method size of Tensor object at 0x7a5bed7a9cb0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9f30> size\n<built-in method size of Tensor object at 0x7a5bed7a8fe0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 44/3907 [00:34<43:31,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d670> size\n<built-in method size of Tensor object at 0x7a5c2225fa10> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cc20> size\n<built-in method size of Tensor object at 0x7a5c2225e660> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 45/3907 [00:34<43:33,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8720> size\n<built-in method size of Tensor object at 0x7a5bed7a9d50> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8ae0> size\n<built-in method size of Tensor object at 0x7a5bed7a9580> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 46/3907 [00:35<43:35,  1.48it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225c5e0> size\n<built-in method size of Tensor object at 0x7a5c2225c770> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225c8b0> size\n<built-in method size of Tensor object at 0x7a5c2225ffb0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 47/3907 [00:36<43:39,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8b30> size\n<built-in method size of Tensor object at 0x7a5bed7abfb0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a93a0> size\n<built-in method size of Tensor object at 0x7a5bed7a8f90> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 48/3907 [00:36<43:40,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab880> size\n<built-in method size of Tensor object at 0x7a5bed7ab790> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225df30> size\n<built-in method size of Tensor object at 0x7a5c2225d990> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 49/3907 [00:37<43:42,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cae0> size\n<built-in method size of Tensor object at 0x7a5c2225d300> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fec0> size\n<built-in method size of Tensor object at 0x7a5c2225c540> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 50/3907 [00:38<43:40,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9760> size\n<built-in method size of Tensor object at 0x7a5bed7ab970> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a93a0> size\n<built-in method size of Tensor object at 0x7a5bed7ab6a0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 51/3907 [00:38<43:39,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cc20> size\n<built-in method size of Tensor object at 0x7a5c2225e0c0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225f6f0> size\n<built-in method size of Tensor object at 0x7a5bed7aa5c0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 52/3907 [00:39<43:39,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e110> size\n<built-in method size of Tensor object at 0x7a5c2225f600> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ec50> size\n<built-in method size of Tensor object at 0x7a5c2225d800> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 53/3907 [00:40<43:39,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa390> size\n<built-in method size of Tensor object at 0x7a5bed7aa390> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225de90> size\n<built-in method size of Tensor object at 0x7a5c2225c270> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 54/3907 [00:40<43:40,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fc40> size\n<built-in method size of Tensor object at 0x7a5c2225f600> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d7b0> size\n<built-in method size of Tensor object at 0x7a5c2225f600> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 55/3907 [00:41<43:39,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5de4c74bd0> size\n<built-in method size of Tensor object at 0x7a5c2225ff60> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c79bd7c90> size\n<built-in method size of Tensor object at 0x7a5c79bd74c0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 56/3907 [00:42<43:40,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e1b0> size\n<built-in method size of Tensor object at 0x7a5c2225ff60> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e430> size\n<built-in method size of Tensor object at 0x7a5bed7a93a0> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 57/3907 [00:42<43:42,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aafc0> size\n<built-in method size of Tensor object at 0x7a5bed7aaa20> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa1b0> size\n<built-in method size of Tensor object at 0x7a5c2225f880> size\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 58/3907 [00:43<43:45,  1.47it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d5d0> size\n<built-in method size of Tensor object at 0x7a5c2225fba0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d7b0> size\n<built-in method size of Tensor object at 0x7a5c2225e930> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 59/3907 [00:44<43:48,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8cc0> size\n<built-in method size of Tensor object at 0x7a5bed7aa8e0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a8bd0> size\n<built-in method size of Tensor object at 0x7a5bed7a8d10> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 60/3907 [00:44<43:51,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225c270> size\n<built-in method size of Tensor object at 0x7a5c2225c270> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa7f0> size\n<built-in method size of Tensor object at 0x7a5bed7ab920> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 61/3907 [00:45<43:55,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c79bd7c90> size\n<built-in method size of Tensor object at 0x7a5c79bd74c0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c79bd76f0> size\n<built-in method size of Tensor object at 0x7a5bed7a8a40> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 62/3907 [00:46<43:57,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aabb0> size\n<built-in method size of Tensor object at 0x7a5bed7a9a80> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9170> size\n<built-in method size of Tensor object at 0x7a5bed7a9440> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 63/3907 [00:46<43:56,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c79bd73d0> size\n<built-in method size of Tensor object at 0x7a5c79bd7bf0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fd80> size\n<built-in method size of Tensor object at 0x7a5c79bd79c0> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 64/3907 [00:47<43:56,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225c770> size\n<built-in method size of Tensor object at 0x7a5c2225d5d0> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225fb50> size\n<built-in method size of Tensor object at 0x7a5c2225de40> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 65/3907 [00:48<43:56,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cc70> size\n<built-in method size of Tensor object at 0x7a5c2225db20> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225cb30> size\n<built-in method size of Tensor object at 0x7a5c2225d670> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 66/3907 [00:49<43:59,  1.46it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa930> size\n<built-in method size of Tensor object at 0x7a5cda708680> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa930> size\n<built-in method size of Tensor object at 0x7a5bed7a9760> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 67/3907 [00:49<44:07,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d6c0> size\n<built-in method size of Tensor object at 0x7a5c2225c130> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225dd00> size\n<built-in method size of Tensor object at 0x7a5c2225d300> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 68/3907 [00:50<44:09,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7a9d50> size\n<built-in method size of Tensor object at 0x7a5bed7a9440> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\n<built-in method size of Tensor object at 0x7a5c2225d030> size\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa9d0> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 69/3907 [00:51<44:12,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225d7b0> size\n<built-in method size of Tensor object at 0x7a5c2225cf90> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225ffb0> size\n<built-in method size of Tensor object at 0x7a5c2225e480> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 70/3907 [00:51<44:10,  1.45it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7aa480> size\n<built-in method size of Tensor object at 0x7a5bed7a9940> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5bed7ab7e0> size\n<built-in method size of Tensor object at 0x7a5bed7abce0> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 71/3907 [00:52<44:15,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c2225e250> size\n<built-in method size of Tensor object at 0x7a5c2225db20> size\ntorch.Size([393216, 25])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c22260450> size\n<built-in method size of Tensor object at 0x7a5c22260040> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 72/3907 [00:53<44:27,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"torch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 3]) torch.Size([393216, 3])\nPOSITIONAL ENCODING\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c222880e0> size\n<built-in method size of Tensor object at 0x7a5bed7aa2a0> size\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\ntorch.Size([393216, 25])\nPOSITIONAL ENCODING 2\ntorch.Size([393216, 3]) OUT SHAPE\nx torch.Size([393216, 3])\n<built-in method size of Tensor object at 0x7a5c22288040> size\n<built-in method size of Tensor object at 0x7a5bed7aad40> size\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 72/3907 [00:53<47:37,  1.34it/s]\n\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}